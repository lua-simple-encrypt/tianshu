"""
PaddleOCR-VL-VLLM è§£æå¼•æ“ (å¤©æ¢ä¸“ç”¨ç”Ÿäº§ç‰ˆ)
å•ä¾‹æ¨¡å¼ï¼Œæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡åŸºç¡€ç‰ˆé¢è¯†åˆ«æ¨¡å‹, OCR/VLM éƒ¨åˆ†é€šè¿‡ OpenAI åè®®è°ƒç”¨è¿œç¨‹ vLLMã€‚

æ ¸å¿ƒé…ç½®ï¼š
- é»˜è®¤ API åœ°å€: http://host.docker.internal:8118/v1 (ç”±ç¯å¢ƒå˜é‡ PADDLE_VLM_URL è¦†ç›–)
- æ¨¡å‹åç§°: PaddleOCR-VL-1.5
"""

import os
import json
import gc
from pathlib import Path
from typing import Optional, Dict, Any
from threading import Lock
from loguru import logger

class PaddleOCRVLVLLMEngine:
    """
    PaddleOCR-VL-VLLM è§£æå¼•æ“
    æ”¯æŒï¼šå¤šé¡µ PDFã€è‡ªåŠ¨è¯­è¨€æ£€æµ‹ã€Markdown ç»“æ„åŒ–è¾“å‡º
    """

    _instance: Optional["PaddleOCRVLVLLMEngine"] = None
    _lock = Lock()
    _pipeline = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, device: str = "cuda:0", vllm_api_base: str = None):
        """
        åˆå§‹åŒ–å¼•æ“

        Args:
            device: é€»è¾‘è®¾å¤‡ ID (ä¾‹å¦‚ "cuda:0")
            vllm_api_base: å¦‚æœæä¾›åˆ™ä½¿ç”¨è¯¥åœ°å€ï¼Œå¦åˆ™æŒ‰ ç¯å¢ƒå˜é‡ -> é»˜è®¤åœ°å€ é¡ºåºæŸ¥æ‰¾
        """
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            self.device = device
            # ä¼˜å…ˆçº§ï¼šå‚æ•°ä¼ é€’ > ç¯å¢ƒå˜é‡ > å¤©æ¢é»˜è®¤åœ°å€
            self.vllm_api_base = (
                vllm_api_base or 
                os.getenv("PADDLE_VLM_URL") or 
                "http://host.docker.internal:8118/v1"
            )

            # æå– GPU ID
            try:
                self.gpu_id = int(device.split(":")[-1]) if "cuda:" in device else 0
            except Exception:
                self.gpu_id = 0

            # éªŒè¯ GPU ç¯å¢ƒ
            self._check_gpu_availability()
            self._initialized = True

            logger.info("=" * 60)
            logger.info("ğŸ”§ PaddleOCR-VL-VLLM Engine Initialized")
            logger.info(f"   ğŸ“ API Endpoint: {self.vllm_api_base}")
            logger.info(f"   ğŸ¯ Local Device: {self.device}")
            logger.info(f"   ğŸ“‚ Model Cache: ~/.paddleocr/models/ (Layout Mode)")
            logger.info("=" * 60)

    def _check_gpu_availability(self):
        """æ£€æŸ¥è¿è¡Œç¯å¢ƒæ˜¯å¦å…·å¤‡ Paddle GPU æ¨ç†èƒ½åŠ›"""
        try:
            import paddle
            if not paddle.is_compiled_with_cuda():
                logger.warning("âš ï¸ PaddlePaddle is NOT compiled with CUDA! Layout detection will be slow.")
            
            gpu_count = paddle.device.cuda.device_count()
            if gpu_count > 0:
                gpu_name = paddle.device.cuda.get_device_name(self.gpu_id)
                logger.info(f"âœ… GPU detected: {gpu_name}")
            else:
                logger.error("âŒ No GPU found! PaddleOCR-VL requires GPU.")
        except ImportError:
            logger.error("âŒ PaddlePaddle not installed. Run: pip install paddlepaddle-gpu")

    def _load_pipeline(self):
        """å»¶è¿ŸåŠ è½½ç®¡é“ï¼Œç¡®ä¿æ˜¾å­˜åœ¨éœ€è¦æ—¶æ‰åˆ†é…"""
        if self._pipeline is not None:
            return self._pipeline

        with self._lock:
            if self._pipeline is not None:
                return self._pipeline

            try:
                import paddle
                from paddleocr import PaddleOCRVL

                # è®¾ç½®å½“å‰è¿›ç¨‹çš„æ˜¾å¡
                if paddle.is_compiled_with_cuda():
                    paddle.set_device(f"gpu:{self.gpu_id}")

                logger.info(f"ğŸ“¥ Loading PaddleOCRVL Pipeline (API: {self.vllm_api_base})...")

                # åˆ›å»ºå®ä¾‹ï¼Œå¯¹æ¥è¿œç¨‹ vLLM
                self._pipeline = PaddleOCRVL(
                    use_doc_orientation_classify=True,
                    use_doc_unwarping=True,
                    use_layout_detection=True,
                    vl_rec_backend="vllm-server",
                    vl_rec_server_url=self.vllm_api_base,
                )
                return self._pipeline

            except Exception as e:
                logger.error(f"âŒ Failed to load PaddleOCRVL pipeline: {e}")
                raise

    def cleanup(self):
        """æ¯æ¬¡æ¨ç†ä»»åŠ¡åæ¸…ç†ä¸´æ—¶ç¼“å­˜ï¼Œé˜²æ­¢æ˜¾å­˜ç¢ç‰‡å †ç§¯"""
        try:
            import paddle
            if paddle.device.is_compiled_with_cuda():
                paddle.device.cuda.empty_cache()
            gc.collect()
            logger.debug("ğŸ§¹ GPU cache cleared after PaddleOCR task")
        except Exception:
            pass

    def parse(self, file_path: str, output_path: str, **kwargs) -> Dict[str, Any]:
        """
        æ ¸å¿ƒè§£æå‡½æ•°

        Args:
            file_path: å¾…è§£ææ–‡ä»¶è·¯å¾„ (PDF/Image)
            output_path: ä»»åŠ¡ä¸“å±è¾“å‡ºç›®å½•
        """
        input_file = Path(file_path)
        out_dir = Path(output_path)
        out_dir.mkdir(parents=True, exist_ok=True)

        pipeline = self._load_pipeline()
        
        try:
            logger.info(f"ğŸš€ [PaddleOCR-VL] Processing: {input_file.name}")
            
            # æ‰§è¡Œæ¨ç† (è‡ªåŠ¨å¤„ç†å¤šé¡µ)
            result = pipeline.predict(str(input_file))
            
            markdown_list = []
            json_list = []

            # éå†è§£æç»“æœ (æ¯ä¸€é¡µ)
            for idx, page_res in enumerate(result, 1):
                page_dir = out_dir / f"page_{idx}"
                page_dir.mkdir(exist_ok=True)

                # ä¿å­˜å•é¡µ JSON å’Œ Markdown (ç”¨äºè°ƒè¯•å’ŒåŸå­å­˜å‚¨)
                if hasattr(page_res, "save_to_json"):
                    page_res.save_to_json(save_path=str(page_dir))
                
                if hasattr(page_res, "markdown"):
                    markdown_list.append(page_res.markdown)
                
                if hasattr(page_res, "json"):
                    json_list.append(page_res.json)

            # åˆå¹¶æ‰€æœ‰é¡µé¢çš„ Markdown
            if hasattr(pipeline, "concatenate_markdown_pages"):
                markdown_text = pipeline.concatenate_markdown_pages(markdown_list)
            else:
                markdown_text = "\n\n---\n\n".join([str(m) for m in markdown_list])

            # ä¿å­˜æœ€ç»ˆåˆå¹¶ç»“æœ
            final_md_path = out_dir / "result.md"
            final_md_path.write_text(markdown_text, encoding="utf-8")
            
            final_json_path = out_dir / "result.json"
            with open(final_json_path, "w", encoding="utf-8") as f:
                json.dump({"pages": json_list, "total": len(result)}, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ… [PaddleOCR-VL] Completed: {len(result)} pages parsed.")

            return {
                "success": True,
                "output_path": str(out_dir),
                "markdown": markdown_text,
                "markdown_file": str(final_md_path),
                "json_file": str(final_json_path)
            }

        except Exception as e:
            logger.error(f"âŒ [PaddleOCR-VL] Parsing Error: {e}")
            raise
        finally:
            self.cleanup()

# å…¨å±€è®¿é—®æ¥å£
_engine = None

def get_engine() -> PaddleOCRVLVLLMEngine:
    """è·å–å•ä¾‹å¼•æ“"""
    global _engine
    if _engine is None:
        _engine = PaddleOCRVLVLLMEngine()
    return _engine
